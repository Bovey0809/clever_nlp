{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df926ae8",
   "metadata": {},
   "source": [
    "# 实验：观测 bert 对 embeddings 模长的影响。\n",
    "\n",
    "实验步骤：\n",
    "- [x] 所有的definiton取出来。\n",
    "- [x] definition进入bert。\n",
    "- [x] 保存所有单词的输出。\n",
    "- [ ] 对输出做统计。\n",
    "- [ ] 得到所有单词的embeddings的norm\n",
    "- [ ] 对比两个norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a267864",
   "metadata": {},
   "source": [
    "## 取出所有 definition，构建 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c15dcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-61bcd1b6d4c45256\n",
      "Reusing dataset csv (/diskb/houbowei/.cache/huggingface/datasets/csv/default-61bcd1b6d4c45256/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47943eed50a24e799e948abc0c534e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /diskb/houbowei/.cache/huggingface/datasets/csv/default-61bcd1b6d4c45256/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-b3e42a1771e2ddf3.arrow\n",
      "Loading cached processed dataset at /diskb/houbowei/.cache/huggingface/datasets/csv/default-61bcd1b6d4c45256/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-87bb01b47c528e30.arrow\n"
     ]
    }
   ],
   "source": [
    "from dataset import build_dataset\n",
    "dataset,tokenizer = build_dataset((0,2))\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# test\n",
    "assert len(dataset['train']) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55330b",
   "metadata": {},
   "source": [
    "## definition 都进入 bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb75a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "collate_function = DataCollatorWithPadding(tokenizer)\n",
    "dataloader = DataLoader(train_dataset, collate_fn=collate_function, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9141612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb9399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cb7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wordnet_data = pd.read_csv(\"./wordnet_bert_common_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "063d96ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'owl': 'nocturnal bird of prey with hawk-like beak and claws and large head with front-facing eyes',\n",
       " 'butte': 'a hill that rises abruptly from the surrounding region; has a flat top and sloping sides'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_to_definitions(words):\n",
    "    global wordnet_data\n",
    "    definitions = dict()\n",
    "    for word in words:\n",
    "        definitions[word] = str(wordnet_data[wordnet_data.words == word].definition.values).strip(\"[]''\")\n",
    "    return definitions\n",
    "\n",
    "# test words_to_definition\n",
    "words_to_definitions([\"owl\", \"butte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0037f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "word_pooler_embeddings_dict = dict()\n",
    "word_hidden_embeddings_dict = dict()\n",
    "bert.to('cuda')\n",
    "bert.eval()\n",
    "\n",
    "for inputs in dataloader:\n",
    "    inputs = {k:v.to('cuda') for k, v in inputs.items()}\n",
    "    word_ids = inputs.pop('word_ids')\n",
    "    words = tokenizer.convert_ids_to_tokens(word_ids)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "        assert bert.training is False\n",
    "    last_hidden_state = outputs['last_hidden_state']\n",
    "    pooler_output = outputs['pooler_output']\n",
    "    word_pooler_embeddings_dict.update(dict(zip(words, pooler_output.cpu().numpy())))\n",
    "    word_hidden_embeddings_dict.update(dict(zip(words, last_hidden_state.mean(dim=1).cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c8e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.197718"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ca36f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_hidden_embeddings_df = pd.DataFrame(word_hidden_embeddings_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e947be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pooler_embeddings_df = pd.DataFrame(word_pooler_embeddings_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4bc61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_norms(word_dict:dict):\n",
    "    d = dict(zip(word_dict.keys(), map(lambda x: np.linalg.norm(x), word_dict.values())))\n",
    "    df = pd.DataFrame(d.items(), columns=['word', 'norm'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ff134d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calculate norms\n",
    "hidden_df = calculate_norms(word_hidden_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48ff05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooler_df = calculate_norms(word_pooler_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03c5d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two norms\n",
    "hidden_pooler_df = pd.merge(hidden_df, pooler_df, on='word', suffixes=['_hidden', '_pooler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "128834d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>norm_hidden</th>\n",
       "      <th>norm_pooler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8564</th>\n",
       "      <td>magazine</td>\n",
       "      <td>8.653953</td>\n",
       "      <td>18.064882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>happily</td>\n",
       "      <td>8.552767</td>\n",
       "      <td>14.256584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>boer</td>\n",
       "      <td>8.501917</td>\n",
       "      <td>21.474812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>garbage</td>\n",
       "      <td>8.859794</td>\n",
       "      <td>18.211678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>liturgy</td>\n",
       "      <td>8.698764</td>\n",
       "      <td>18.120737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>spat</td>\n",
       "      <td>9.221212</td>\n",
       "      <td>14.954306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>cologne</td>\n",
       "      <td>8.350233</td>\n",
       "      <td>18.897917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>spencer</td>\n",
       "      <td>8.036829</td>\n",
       "      <td>21.776302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>gubernatorial</td>\n",
       "      <td>10.012076</td>\n",
       "      <td>17.228092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>unfortunate</td>\n",
       "      <td>8.956439</td>\n",
       "      <td>15.803585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  norm_hidden  norm_pooler\n",
       "8564        magazine     8.653953    18.064882\n",
       "10833        happily     8.552767    14.256584\n",
       "11565           boer     8.501917    21.474812\n",
       "3869         garbage     8.859794    18.211678\n",
       "13840        liturgy     8.698764    18.120737\n",
       "5831            spat     9.221212    14.954306\n",
       "2519         cologne     8.350233    18.897917\n",
       "4683         spencer     8.036829    21.776302\n",
       "10604  gubernatorial    10.012076    17.228092\n",
       "13775    unfortunate     8.956439    15.803585"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_pooler_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cc5763f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_hidden</th>\n",
       "      <th>norm_pooler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14510.000000</td>\n",
       "      <td>14510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.980854</td>\n",
       "      <td>17.567572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.549578</td>\n",
       "      <td>1.974311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.491759</td>\n",
       "      <td>12.548604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.593598</td>\n",
       "      <td>15.979658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.934441</td>\n",
       "      <td>17.657382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.307274</td>\n",
       "      <td>19.114820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.957676</td>\n",
       "      <td>23.039471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        norm_hidden   norm_pooler\n",
       "count  14510.000000  14510.000000\n",
       "mean       8.980854     17.567572\n",
       "std        0.549578      1.974311\n",
       "min        7.491759     12.548604\n",
       "25%        8.593598     15.979658\n",
       "50%        8.934441     17.657382\n",
       "75%        9.307274     19.114820\n",
       "max       12.957676     23.039471"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_pooler_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a26f18",
   "metadata": {},
   "source": [
    "使用 hidden 层而不是 pooler 层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc5fe22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word embeddings from bert embeddings layer.\n",
    "word_embeddings_dict = dict()\n",
    "\n",
    "for inputs in dataloader:\n",
    "    inputs = {k:v.to('cuda') for k, v in inputs.items()}\n",
    "    word_ids = inputs.pop('word_ids')\n",
    "    words = tokenizer.convert_ids_to_tokens(word_ids)\n",
    "    embeddings = bert.embeddings.word_embeddings.state_dict()['weight'][word_ids]\n",
    "    word_embeddings_dict.update(dict(zip(words, embeddings.detach().cpu().numpy())))\n",
    "\n",
    "original_word_norm_df = calculate_norms(word_embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8bafd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.merge(original_word_norm_df, hidden_pooler_df, on='word', suffixes=['original', 'hidden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06031c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm</th>\n",
       "      <th>norm_hidden</th>\n",
       "      <th>norm_pooler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14510.000000</td>\n",
       "      <td>14510.000000</td>\n",
       "      <td>14510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.339519</td>\n",
       "      <td>8.980854</td>\n",
       "      <td>17.567572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.151899</td>\n",
       "      <td>0.549578</td>\n",
       "      <td>1.974311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.866191</td>\n",
       "      <td>7.491759</td>\n",
       "      <td>12.548604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.233141</td>\n",
       "      <td>8.593598</td>\n",
       "      <td>15.979658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.355623</td>\n",
       "      <td>8.934441</td>\n",
       "      <td>17.657382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.452249</td>\n",
       "      <td>9.307274</td>\n",
       "      <td>19.114820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.823229</td>\n",
       "      <td>12.957676</td>\n",
       "      <td>23.039471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               norm   norm_hidden   norm_pooler\n",
       "count  14510.000000  14510.000000  14510.000000\n",
       "mean       1.339519      8.980854     17.567572\n",
       "std        0.151899      0.549578      1.974311\n",
       "min        0.866191      7.491759     12.548604\n",
       "25%        1.233141      8.593598     15.979658\n",
       "50%        1.355623      8.934441     17.657382\n",
       "75%        1.452249      9.307274     19.114820\n",
       "max        1.823229     12.957676     23.039471"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
